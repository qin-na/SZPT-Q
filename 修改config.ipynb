{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZNI-Yq9mdenV-AniUwHVSn5AzJOqTREj",
      "authorship_tag": "ABX9TyNkq3r3yk1OzzXnIuWVVY87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b2dd6714c2e4405a85fb6ecfdd7b190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c63de828643d4224b6a5da79e53b95e9",
              "IPY_MODEL_56074051f85b4003af62bb289033ec93",
              "IPY_MODEL_639fc6cecf554a59ba1827ad28e341fa"
            ],
            "layout": "IPY_MODEL_33764ce3dcc0478fa7299493ed866b82"
          }
        },
        "c63de828643d4224b6a5da79e53b95e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8328a131d5154b57a32610196e092b5d",
            "placeholder": "​",
            "style": "IPY_MODEL_5643f01d63f84bd5a8a66bf02404fb3c",
            "value": "Downloading builder script: "
          }
        },
        "56074051f85b4003af62bb289033ec93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328b2c39703944cc997a03e2d782ae03",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_202bdcc9a1dc4f6b90954f4adcbc9ab6",
            "value": 2472
          }
        },
        "639fc6cecf554a59ba1827ad28e341fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d8574dca954ff79ab9d417ba9cd6d1",
            "placeholder": "​",
            "style": "IPY_MODEL_48de5d219ef846d7bba107913fcdaf6f",
            "value": " 6.33k/? [00:00&lt;00:00, 195kB/s]"
          }
        },
        "33764ce3dcc0478fa7299493ed866b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8328a131d5154b57a32610196e092b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5643f01d63f84bd5a8a66bf02404fb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "328b2c39703944cc997a03e2d782ae03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202bdcc9a1dc4f6b90954f4adcbc9ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03d8574dca954ff79ab9d417ba9cd6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48de5d219ef846d7bba107913fcdaf6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qin-na/SZPT-Q/blob/main/%E4%BF%AE%E6%94%B9config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES3rjNBp46vD",
        "outputId": "cdb3b5a8-15c7-478e-b5ad-d3f6061b37be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2cbef2-8f6b-485b-a158-3f0a5b37b79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=efae7ac0f4045a5ea2e793aea7b39f6bc055474af91442c5f0f494a08f1b4454\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tokenizers, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, seqeval, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 safetensors-0.3.3 seqeval-1.2.2 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.24.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DASrghruoTis",
        "outputId": "11a4d2db-71b0-4406-b8d4-41172f89040c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.24.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2023.7.22)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.32.1\n",
            "    Uninstalling transformers-4.32.1:\n",
            "      Successfully uninstalled transformers-4.32.1\n",
            "Successfully installed transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
        "model_checkpoint = \"/content/drive/MyDrive/PolymerNER\"\n",
        "#model_checkpoint = \"pranav-s/MaterialsBERT\"\n",
        "batch_size = 16\n",
        "truncation=True\n",
        "# 加载数据\n",
        "from datasets import load_dataset, load_metric, load_from_disk\n",
        "datasets = load_from_disk(\"/content/drive/MyDrive/autotrain-data-automatic/processed\")\n",
        "#datasets\n",
        "datasets[\"train\"][0]\n",
        "datasets[\"train\"].features[f\"tags\"]\n",
        "label_list = datasets[\"train\"].features[f\"tags\"].feature.names\n",
        "#label_list\n",
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))\n",
        "#show_random_elements(datasets[\"train\"])\n",
        "\n",
        "# 预处理数据\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "import transformers\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
        "tokenizer(\"Hello, this is one sentence!\")\n",
        "tokenizer([\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"], is_split_into_words=True)\n",
        "example = datasets[\"train\"][4]\n",
        "print(example[\"tokens\"])\n",
        "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "print(tokens)\n",
        "len(example[f\"tags\"]), len(tokenized_input[\"input_ids\"])\n",
        "print(tokenized_input.word_ids())\n",
        "word_ids = tokenized_input.word_ids()\n",
        "aligned_labels = [-100 if i is None else example[f\"tags\"][i] for i in word_ids]\n",
        "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))\n",
        "label_all_tokens = True\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], max_length=512, truncation=True,return_tensors='pt', padding=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "tokenize_and_align_labels(datasets['train'][:5])\n",
        "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
        "# 微调模型\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list),ignore_mismatched_sizes=True,max_length=512)\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=100,\n",
        "    weight_decay=0.01,\n",
        "    #push_to_hub=True,\n",
        "    push_to_hub=False\n",
        ")\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")\n",
        "labels = [label_list[i] for i in example[f\"tags\"]]\n",
        "metric.compute(predictions=[labels], references=[labels])\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6b2dd6714c2e4405a85fb6ecfdd7b190",
            "c63de828643d4224b6a5da79e53b95e9",
            "56074051f85b4003af62bb289033ec93",
            "639fc6cecf554a59ba1827ad28e341fa",
            "33764ce3dcc0478fa7299493ed866b82",
            "8328a131d5154b57a32610196e092b5d",
            "5643f01d63f84bd5a8a66bf02404fb3c",
            "328b2c39703944cc997a03e2d782ae03",
            "202bdcc9a1dc4f6b90954f4adcbc9ab6",
            "03d8574dca954ff79ab9d417ba9cd6d1",
            "48de5d219ef846d7bba107913fcdaf6f"
          ]
        },
        "id": "4knsZsSjmiig",
        "outputId": "22148217-4f08-4818-972a-7a97e3492a75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Exploring', 'hydrogen', 'evolution', 'reaction', '(HER)', 'catalyst', 'with', 'highly', 'catalytic', 'features', 'in', 'alkaline', 'conditions', 'is', 'considered', 'as', 'significance', 'for', 'water', 'splitting.', 'In', 'this', 'study,', 'a', 'general', 'and', 'simple', 'method', 'was', 'developed', 'to', 'prepare', 'flower-like', 'platinum-cobalt-ruthenium', 'alloy', 'nanoassemblies', '(PtCoRu', 'NAs)', 'by', 'using', 'murexide', 'and', 'cetyltrimethylammonium', 'chloride', '(CTAC)', 'as', 'the', 'co-structure-directing', 'agents.', 'Benefiting', 'from', 'the', 'structural', 'advantages', 'and', 'multimetallic', 'compositions,', 'the', 'as-prepared', 'PtCoRu', 'NAs', 'displayed', 'remarkably', 'enhanced', 'electrocatalytic', 'performance', 'for', 'the', 'HER', 'in', '1.0', 'M', 'KOH,', 'with', 'a', 'low', 'overpotential', '(η,', '22', 'mV', ')', 'to', 'drive', '10', 'mA', 'cm<sup>-2</sup>', ',', 'small', 'Tafel', 'slope', '(', '46', 'mV', 'dec<sup>-1</sup>', '),', 'and', 'high', 'exchange', 'current', 'density', '(j<sub>0</sub>,', '3.30', 'mA', 'cm<sup>-2</sup>', ')', 'during', 'the', 'long-term', 'electrolysis.', 'The', 'as-developed', 'strategy', 'sheds', 'some', 'valuable', 'guidelines', 'for', 'preparing', 'advanced', 'multimetallic', 'catalysts', 'for', 'production', 'of', 'hydrogen', 'in', 'fuel', 'cells.', '</p>', '<p>']\n",
            "['[CLS]', 'exploring', 'hydrogen', 'evolution', 'reaction', '(', 'her', ')', 'catalyst', 'with', 'highly', 'catalytic', 'features', 'in', 'alkaline', 'conditions', 'is', 'considered', 'as', 'significance', 'for', 'water', 'splitting', '.', 'in', 'this', 'study', ',', 'a', 'general', 'and', 'simple', 'method', 'was', 'developed', 'to', 'prepare', 'flower', '-', 'like', 'platinum', '-', 'cobalt', '-', 'rut', '##hen', '##ium', 'alloy', 'nano', '##ass', '##embl', '##ies', '(', 'ptc', '##or', '##u', 'nas', ')', 'by', 'using', 'mur', '##ex', '##ide', 'and', 'cet', '##yl', '##tr', '##imethyl', '##ammonium', 'chloride', '(', 'cta', '##c', ')', 'as', 'the', 'co', '-', 'structure', '-', 'directing', 'agents', '.', 'benefit', '##ing', 'from', 'the', 'structural', 'advantages', 'and', 'multim', '##etal', '##lic', 'compositions', ',', 'the', 'as', '-', 'prepared', 'ptc', '##or', '##u', 'nas', 'displayed', 'remarkably', 'enhanced', 'electroc', '##atalytic', 'performance', 'for', 'the', 'her', 'in', '1', '.', '0', 'm', 'koh', ',', 'with', 'a', 'low', 'over', '##pot', '##ential', '(', 'η', ',', '22', 'mv', ')', 'to', 'drive', '10', 'ma', 'cm', '<', 'sup', '>', '-', '2', '<', '/', 'sup', '>', ',', 'small', 'taf', '##el', 'slope', '(', '46', 'mv', 'dec', '<', 'sup', '>', '-', '1', '<', '/', 'sup', '>', ')', ',', 'and', 'high', 'exchange', 'current', 'density', '(', 'j', '<', 'sub', '>', '0', '<', '/', 'sub', '>', ',', '3', '.', '30', 'ma', 'cm', '<', 'sup', '>', '-', '2', '<', '/', 'sup', '>', ')', 'during', 'the', 'long', '-', 'term', 'electroly', '##sis', '.', 'the', 'as', '-', 'developed', 'strategy', 'shed', '##s', 'some', 'valuable', 'guidelines', 'for', 'preparing', 'advanced', 'multim', '##etal', '##lic', 'catalysts', 'for', 'production', 'of', 'hydrogen', 'in', 'fuel', 'cells', '.', '<', '/', 'p', '>', '<', 'p', '>', '[SEP]']\n",
            "[None, 0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 34, 35, 35, 35, 35, 36, 36, 36, 36, 37, 37, 38, 39, 40, 40, 40, 41, 42, 42, 42, 42, 42, 43, 44, 44, 44, 44, 45, 46, 47, 47, 47, 47, 47, 48, 48, 49, 49, 50, 51, 52, 53, 54, 55, 55, 55, 56, 56, 57, 58, 58, 58, 59, 59, 59, 60, 61, 62, 63, 64, 64, 65, 66, 67, 68, 69, 70, 70, 70, 71, 72, 72, 73, 74, 75, 76, 76, 76, 77, 77, 77, 78, 79, 80, 81, 82, 83, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 87, 88, 88, 89, 90, 91, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 95, 96, 97, 98, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 105, 106, 107, 107, 107, 108, 108, 108, 109, 110, 110, 110, 111, 112, 112, 113, 114, 115, 116, 117, 118, 119, 119, 119, 120, 121, 122, 123, 124, 125, 126, 127, 127, 128, 128, 128, 128, 129, 129, 129, None]\n",
            "237 237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/PolymerNER and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-5-4f7ab22bee50>:103: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b2dd6714c2e4405a85fb6ecfdd7b190"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 168\n",
            "  Num Epochs = 100\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1100\n",
            "  Number of trainable parameters = 108896262\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1100/1100 29:13, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.350382</td>\n",
              "      <td>0.432018</td>\n",
              "      <td>0.419149</td>\n",
              "      <td>0.425486</td>\n",
              "      <td>0.891706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.215097</td>\n",
              "      <td>0.619850</td>\n",
              "      <td>0.704255</td>\n",
              "      <td>0.659363</td>\n",
              "      <td>0.930094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204286</td>\n",
              "      <td>0.643527</td>\n",
              "      <td>0.729787</td>\n",
              "      <td>0.683948</td>\n",
              "      <td>0.933494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.188936</td>\n",
              "      <td>0.690909</td>\n",
              "      <td>0.727660</td>\n",
              "      <td>0.708808</td>\n",
              "      <td>0.937319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.197695</td>\n",
              "      <td>0.751064</td>\n",
              "      <td>0.751064</td>\n",
              "      <td>0.751064</td>\n",
              "      <td>0.941851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.191797</td>\n",
              "      <td>0.778523</td>\n",
              "      <td>0.740426</td>\n",
              "      <td>0.758997</td>\n",
              "      <td>0.942347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.206860</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.774468</td>\n",
              "      <td>0.765510</td>\n",
              "      <td>0.943976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.217071</td>\n",
              "      <td>0.741597</td>\n",
              "      <td>0.751064</td>\n",
              "      <td>0.746300</td>\n",
              "      <td>0.942701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.226155</td>\n",
              "      <td>0.724000</td>\n",
              "      <td>0.770213</td>\n",
              "      <td>0.746392</td>\n",
              "      <td>0.941568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.235814</td>\n",
              "      <td>0.716505</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.749239</td>\n",
              "      <td>0.940152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.235912</td>\n",
              "      <td>0.740286</td>\n",
              "      <td>0.770213</td>\n",
              "      <td>0.754953</td>\n",
              "      <td>0.943622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.241267</td>\n",
              "      <td>0.731760</td>\n",
              "      <td>0.725532</td>\n",
              "      <td>0.728632</td>\n",
              "      <td>0.941710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.240006</td>\n",
              "      <td>0.741483</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.763674</td>\n",
              "      <td>0.944260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.246686</td>\n",
              "      <td>0.735060</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.260228</td>\n",
              "      <td>0.704120</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.749004</td>\n",
              "      <td>0.942418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.274500</td>\n",
              "      <td>0.699627</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.940647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.279485</td>\n",
              "      <td>0.707843</td>\n",
              "      <td>0.768085</td>\n",
              "      <td>0.736735</td>\n",
              "      <td>0.941639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.285061</td>\n",
              "      <td>0.710425</td>\n",
              "      <td>0.782979</td>\n",
              "      <td>0.744939</td>\n",
              "      <td>0.942701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.291785</td>\n",
              "      <td>0.704673</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.750249</td>\n",
              "      <td>0.941497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.290102</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.735793</td>\n",
              "      <td>0.940647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.292388</td>\n",
              "      <td>0.728346</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.756646</td>\n",
              "      <td>0.942135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.311452</td>\n",
              "      <td>0.698355</td>\n",
              "      <td>0.812766</td>\n",
              "      <td>0.751229</td>\n",
              "      <td>0.940860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.295059</td>\n",
              "      <td>0.695167</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.742063</td>\n",
              "      <td>0.941710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.303823</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.764948</td>\n",
              "      <td>0.943693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.314684</td>\n",
              "      <td>0.695167</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.742063</td>\n",
              "      <td>0.940364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.330319</td>\n",
              "      <td>0.708561</td>\n",
              "      <td>0.827660</td>\n",
              "      <td>0.763494</td>\n",
              "      <td>0.941922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.328151</td>\n",
              "      <td>0.705323</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.744980</td>\n",
              "      <td>0.940718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.323641</td>\n",
              "      <td>0.689591</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.736111</td>\n",
              "      <td>0.940010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.317079</td>\n",
              "      <td>0.718929</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.757301</td>\n",
              "      <td>0.943055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.331520</td>\n",
              "      <td>0.706542</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.752239</td>\n",
              "      <td>0.940647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.320589</td>\n",
              "      <td>0.733855</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.764526</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.337528</td>\n",
              "      <td>0.691892</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>0.749268</td>\n",
              "      <td>0.940506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.332237</td>\n",
              "      <td>0.704762</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.743719</td>\n",
              "      <td>0.941426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.330941</td>\n",
              "      <td>0.698864</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.739479</td>\n",
              "      <td>0.941568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.316619</td>\n",
              "      <td>0.699627</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.342296</td>\n",
              "      <td>0.702804</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.748259</td>\n",
              "      <td>0.941568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.323989</td>\n",
              "      <td>0.723608</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.760848</td>\n",
              "      <td>0.943480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.336183</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.738492</td>\n",
              "      <td>0.939160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340273</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.767322</td>\n",
              "      <td>0.946030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.348327</td>\n",
              "      <td>0.691203</td>\n",
              "      <td>0.819149</td>\n",
              "      <td>0.749757</td>\n",
              "      <td>0.942418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.328295</td>\n",
              "      <td>0.721281</td>\n",
              "      <td>0.814894</td>\n",
              "      <td>0.765235</td>\n",
              "      <td>0.944543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.335342</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>0.760396</td>\n",
              "      <td>0.943835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.347880</td>\n",
              "      <td>0.699065</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.744279</td>\n",
              "      <td>0.942489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.339819</td>\n",
              "      <td>0.704762</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.743719</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340311</td>\n",
              "      <td>0.707948</td>\n",
              "      <td>0.814894</td>\n",
              "      <td>0.757666</td>\n",
              "      <td>0.944047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.343778</td>\n",
              "      <td>0.714012</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.750757</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.344967</td>\n",
              "      <td>0.717514</td>\n",
              "      <td>0.810638</td>\n",
              "      <td>0.761239</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.354870</td>\n",
              "      <td>0.721591</td>\n",
              "      <td>0.810638</td>\n",
              "      <td>0.763527</td>\n",
              "      <td>0.943197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.358224</td>\n",
              "      <td>0.717472</td>\n",
              "      <td>0.821277</td>\n",
              "      <td>0.765873</td>\n",
              "      <td>0.943622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.360383</td>\n",
              "      <td>0.730038</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.352525</td>\n",
              "      <td>0.725379</td>\n",
              "      <td>0.814894</td>\n",
              "      <td>0.767535</td>\n",
              "      <td>0.943905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.350185</td>\n",
              "      <td>0.735922</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.769543</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.357599</td>\n",
              "      <td>0.730038</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.360143</td>\n",
              "      <td>0.719397</td>\n",
              "      <td>0.812766</td>\n",
              "      <td>0.763237</td>\n",
              "      <td>0.943835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.368878</td>\n",
              "      <td>0.719697</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.761523</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.373564</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.942843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.365839</td>\n",
              "      <td>0.712687</td>\n",
              "      <td>0.812766</td>\n",
              "      <td>0.759443</td>\n",
              "      <td>0.941497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.364390</td>\n",
              "      <td>0.705224</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.751491</td>\n",
              "      <td>0.941426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.364915</td>\n",
              "      <td>0.709738</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.754980</td>\n",
              "      <td>0.942630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.367464</td>\n",
              "      <td>0.707090</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.753479</td>\n",
              "      <td>0.941072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.373578</td>\n",
              "      <td>0.706865</td>\n",
              "      <td>0.810638</td>\n",
              "      <td>0.755203</td>\n",
              "      <td>0.941922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.371604</td>\n",
              "      <td>0.707547</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.364535</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.942701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.361809</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.751745</td>\n",
              "      <td>0.943055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.366519</td>\n",
              "      <td>0.705009</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.753221</td>\n",
              "      <td>0.942772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.367868</td>\n",
              "      <td>0.687616</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.735905</td>\n",
              "      <td>0.942206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.367294</td>\n",
              "      <td>0.704120</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.749004</td>\n",
              "      <td>0.941993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.367913</td>\n",
              "      <td>0.702804</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.748259</td>\n",
              "      <td>0.942843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.367554</td>\n",
              "      <td>0.699262</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.749012</td>\n",
              "      <td>0.941214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.370320</td>\n",
              "      <td>0.716763</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.752275</td>\n",
              "      <td>0.942701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.370935</td>\n",
              "      <td>0.717308</td>\n",
              "      <td>0.793617</td>\n",
              "      <td>0.753535</td>\n",
              "      <td>0.942701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.374825</td>\n",
              "      <td>0.705660</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.748000</td>\n",
              "      <td>0.942772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.377110</td>\n",
              "      <td>0.700935</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.942914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.377580</td>\n",
              "      <td>0.699262</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.749012</td>\n",
              "      <td>0.941993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.374297</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.744368</td>\n",
              "      <td>0.941993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.372235</td>\n",
              "      <td>0.693015</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.942772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.378178</td>\n",
              "      <td>0.697802</td>\n",
              "      <td>0.810638</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.942560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.374372</td>\n",
              "      <td>0.702087</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.742227</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.376132</td>\n",
              "      <td>0.704198</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.742455</td>\n",
              "      <td>0.944260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.377619</td>\n",
              "      <td>0.699627</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.943339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.378512</td>\n",
              "      <td>0.702804</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.748259</td>\n",
              "      <td>0.943410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.381122</td>\n",
              "      <td>0.699627</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.385785</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.942630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.385310</td>\n",
              "      <td>0.697936</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.741775</td>\n",
              "      <td>0.942914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.388534</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.942985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.391493</td>\n",
              "      <td>0.693015</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.941993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.393335</td>\n",
              "      <td>0.689214</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.741396</td>\n",
              "      <td>0.942206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.395734</td>\n",
              "      <td>0.696133</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.746298</td>\n",
              "      <td>0.941993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.394297</td>\n",
              "      <td>0.688766</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.738401</td>\n",
              "      <td>0.942418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.391231</td>\n",
              "      <td>0.696462</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.742800</td>\n",
              "      <td>0.942772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.388200</td>\n",
              "      <td>0.697936</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.741775</td>\n",
              "      <td>0.943339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.385122</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>0.942985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.384894</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.741036</td>\n",
              "      <td>0.942914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.384755</td>\n",
              "      <td>0.695733</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.743310</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.385877</td>\n",
              "      <td>0.702247</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.747012</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.386782</td>\n",
              "      <td>0.700935</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.943339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.386159</td>\n",
              "      <td>0.699627</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.943339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.386243</td>\n",
              "      <td>0.698885</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.746032</td>\n",
              "      <td>0.943197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.386124</td>\n",
              "      <td>0.700186</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.746773</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.386074</td>\n",
              "      <td>0.700186</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.746773</td>\n",
              "      <td>0.943268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to PolymerNER-finetuned-ner/checkpoint-500\n",
            "Configuration saved in PolymerNER-finetuned-ner/checkpoint-500/config.json\n",
            "Model weights saved in PolymerNER-finetuned-ner/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in PolymerNER-finetuned-ner/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in PolymerNER-finetuned-ner/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to PolymerNER-finetuned-ner/checkpoint-1000\n",
            "Configuration saved in PolymerNER-finetuned-ner/checkpoint-1000/config.json\n",
            "Model weights saved in PolymerNER-finetuned-ner/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in PolymerNER-finetuned-ner/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in PolymerNER-finetuned-ner/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens. If tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1100, training_loss=0.03534715988419273, metrics={'train_runtime': 1758.4193, 'train_samples_per_second': 9.554, 'train_steps_per_second': 0.626, 'total_flos': 4389944264294400.0, 'train_loss': 0.03534715988419273, 'epoch': 100.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWfa7qOi6_Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "Bs5L-Ji3pFJL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}