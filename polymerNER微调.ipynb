{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZGhFG-rz9ItDTYaVAQtDZPqX2QjvTzk9",
      "authorship_tag": "ABX9TyP2jr/g2QKFL7K4vcHqCdBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2832898d963d444db4994c13b84bfc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05e44ebb6e08457d886dd4b149c8fcbe",
              "IPY_MODEL_f34a6a057b8f49f5a726aa7d0f8e6a0d",
              "IPY_MODEL_353f273186474530b88d0f006e97e34d"
            ],
            "layout": "IPY_MODEL_38cea7795ed34c6dad83cb74fd006db0"
          }
        },
        "05e44ebb6e08457d886dd4b149c8fcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030bc61029514175bf3d42b86869ae32",
            "placeholder": "​",
            "style": "IPY_MODEL_c069bea6b6794fc3b715bc46e19b6c9b",
            "value": "Downloading builder script: "
          }
        },
        "f34a6a057b8f49f5a726aa7d0f8e6a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d92cf314ac14afc8456790013c883be",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e28f28537b3044cf8a0d808e8e8d2496",
            "value": 2472
          }
        },
        "353f273186474530b88d0f006e97e34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca99a16334eb4d08930def49ebd32052",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb9df159a7043308dace9110e2e61b1",
            "value": " 6.33k/? [00:00&lt;00:00, 116kB/s]"
          }
        },
        "38cea7795ed34c6dad83cb74fd006db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030bc61029514175bf3d42b86869ae32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c069bea6b6794fc3b715bc46e19b6c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d92cf314ac14afc8456790013c883be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28f28537b3044cf8a0d808e8e8d2496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca99a16334eb4d08930def49ebd32052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb9df159a7043308dace9110e2e61b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qin-na/SZPT-Q/blob/main/polymerNER%E5%BE%AE%E8%B0%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a426f55a-9c8f-4d3c-c515-61ca924e875e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=d56b68f3afcea06f55f68c8bf68e373222e4d9ad0da6ede51fcb9a8a2d3c4d0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tokenizers, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, seqeval, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 safetensors-0.3.3 seqeval-1.2.2 tokenizers-0.13.3 transformers-4.32.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.24.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "DASrghruoTis",
        "outputId": "59590baf-2c27-4918-884f-50fd39259f8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.24.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.24.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.24.0) (2023.7.22)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.32.0\n",
            "    Uninstalling transformers-4.32.0:\n",
            "      Successfully uninstalled transformers-4.32.0\n",
            "Successfully installed transformers-4.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
        "model_checkpoint = \"pranav-s/PolymerNER\"\n",
        "batch_size = 16\n",
        "truncation=True\n",
        "# 加载数据\n",
        "from datasets import load_dataset, load_metric, load_from_disk\n",
        "datasets = load_from_disk(\"/content/drive/MyDrive/autotrain-data-automatic/processed\")\n",
        "#datasets\n",
        "datasets[\"train\"][0]\n",
        "datasets[\"train\"].features[f\"tags\"]\n",
        "label_list = datasets[\"train\"].features[f\"tags\"].feature.names\n",
        "#label_list\n",
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))\n",
        "#show_random_elements(datasets[\"train\"])\n",
        "\n",
        "# 预处理数据\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "import transformers\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
        "tokenizer(\"Hello, this is one sentence!\")\n",
        "tokenizer([\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"], is_split_into_words=True)\n",
        "example = datasets[\"train\"][4]\n",
        "print(example[\"tokens\"])\n",
        "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "print(tokens)\n",
        "len(example[f\"tags\"]), len(tokenized_input[\"input_ids\"])\n",
        "print(tokenized_input.word_ids())\n",
        "word_ids = tokenized_input.word_ids()\n",
        "aligned_labels = [-100 if i is None else example[f\"tags\"][i] for i in word_ids]\n",
        "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))\n",
        "label_all_tokens = True\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], max_length=512, truncation=True,return_tensors='pt', padding=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "tokenize_and_align_labels(datasets['train'][:5])\n",
        "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
        "# 微调模型\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list),ignore_mismatched_sizes=True,max_length=512)\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=100,\n",
        "    weight_decay=0.01,\n",
        "    #push_to_hub=True,\n",
        "    push_to_hub=False\n",
        ")\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")\n",
        "labels = [label_list[i] for i in example[f\"tags\"]]\n",
        "metric.compute(predictions=[labels], references=[labels])\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2832898d963d444db4994c13b84bfc26",
            "05e44ebb6e08457d886dd4b149c8fcbe",
            "f34a6a057b8f49f5a726aa7d0f8e6a0d",
            "353f273186474530b88d0f006e97e34d",
            "38cea7795ed34c6dad83cb74fd006db0",
            "030bc61029514175bf3d42b86869ae32",
            "c069bea6b6794fc3b715bc46e19b6c9b",
            "7d92cf314ac14afc8456790013c883be",
            "e28f28537b3044cf8a0d808e8e8d2496",
            "ca99a16334eb4d08930def49ebd32052",
            "0bb9df159a7043308dace9110e2e61b1"
          ]
        },
        "id": "4knsZsSjmiig",
        "outputId": "413de43e-c68f-4f27-cfa7-bd1334121dad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Exploring', 'hydrogen', 'evolution', 'reaction', '(HER)', 'catalyst', 'with', 'highly', 'catalytic', 'features', 'in', 'alkaline', 'conditions', 'is', 'considered', 'as', 'significance', 'for', 'water', 'splitting.', 'In', 'this', 'study,', 'a', 'general', 'and', 'simple', 'method', 'was', 'developed', 'to', 'prepare', 'flower-like', 'platinum-cobalt-ruthenium', 'alloy', 'nanoassemblies', '(PtCoRu', 'NAs)', 'by', 'using', 'murexide', 'and', 'cetyltrimethylammonium', 'chloride', '(CTAC)', 'as', 'the', 'co-structure-directing', 'agents.', 'Benefiting', 'from', 'the', 'structural', 'advantages', 'and', 'multimetallic', 'compositions,', 'the', 'as-prepared', 'PtCoRu', 'NAs', 'displayed', 'remarkably', 'enhanced', 'electrocatalytic', 'performance', 'for', 'the', 'HER', 'in', '1.0', 'M', 'KOH,', 'with', 'a', 'low', 'overpotential', '(η,', '22', 'mV', ')', 'to', 'drive', '10', 'mA', 'cm<sup>-2</sup>', ',', 'small', 'Tafel', 'slope', '(', '46', 'mV', 'dec<sup>-1</sup>', '),', 'and', 'high', 'exchange', 'current', 'density', '(j<sub>0</sub>,', '3.30', 'mA', 'cm<sup>-2</sup>', ')', 'during', 'the', 'long-term', 'electrolysis.', 'The', 'as-developed', 'strategy', 'sheds', 'some', 'valuable', 'guidelines', 'for', 'preparing', 'advanced', 'multimetallic', 'catalysts', 'for', 'production', 'of', 'hydrogen', 'in', 'fuel', 'cells.', '</p>', '<p>']\n",
            "['[CLS]', 'exploring', 'hydrogen', 'evolution', 'reaction', '(', 'her', ')', 'catalyst', 'with', 'highly', 'catalytic', 'features', 'in', 'alkaline', 'conditions', 'is', 'considered', 'as', 'significance', 'for', 'water', 'splitting', '.', 'in', 'this', 'study', ',', 'a', 'general', 'and', 'simple', 'method', 'was', 'developed', 'to', 'prepare', 'flower', '-', 'like', 'platinum', '-', 'cobalt', '-', 'rut', '##hen', '##ium', 'alloy', 'nano', '##ass', '##embl', '##ies', '(', 'ptc', '##or', '##u', 'nas', ')', 'by', 'using', 'mur', '##ex', '##ide', 'and', 'cet', '##yl', '##tr', '##imethyl', '##ammonium', 'chloride', '(', 'cta', '##c', ')', 'as', 'the', 'co', '-', 'structure', '-', 'directing', 'agents', '.', 'benefit', '##ing', 'from', 'the', 'structural', 'advantages', 'and', 'multim', '##etal', '##lic', 'compositions', ',', 'the', 'as', '-', 'prepared', 'ptc', '##or', '##u', 'nas', 'displayed', 'remarkably', 'enhanced', 'electroc', '##atalytic', 'performance', 'for', 'the', 'her', 'in', '1', '.', '0', 'm', 'koh', ',', 'with', 'a', 'low', 'over', '##pot', '##ential', '(', 'η', ',', '22', 'mv', ')', 'to', 'drive', '10', 'ma', 'cm', '<', 'sup', '>', '-', '2', '<', '/', 'sup', '>', ',', 'small', 'taf', '##el', 'slope', '(', '46', 'mv', 'dec', '<', 'sup', '>', '-', '1', '<', '/', 'sup', '>', ')', ',', 'and', 'high', 'exchange', 'current', 'density', '(', 'j', '<', 'sub', '>', '0', '<', '/', 'sub', '>', ',', '3', '.', '30', 'ma', 'cm', '<', 'sup', '>', '-', '2', '<', '/', 'sup', '>', ')', 'during', 'the', 'long', '-', 'term', 'electroly', '##sis', '.', 'the', 'as', '-', 'developed', 'strategy', 'shed', '##s', 'some', 'valuable', 'guidelines', 'for', 'preparing', 'advanced', 'multim', '##etal', '##lic', 'catalysts', 'for', 'production', 'of', 'hydrogen', 'in', 'fuel', 'cells', '.', '<', '/', 'p', '>', '<', 'p', '>', '[SEP]']\n",
            "[None, 0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 20, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 34, 35, 35, 35, 35, 36, 36, 36, 36, 37, 37, 38, 39, 40, 40, 40, 41, 42, 42, 42, 42, 42, 43, 44, 44, 44, 44, 45, 46, 47, 47, 47, 47, 47, 48, 48, 49, 49, 50, 51, 52, 53, 54, 55, 55, 55, 56, 56, 57, 58, 58, 58, 59, 59, 59, 60, 61, 62, 63, 64, 64, 65, 66, 67, 68, 69, 70, 70, 70, 71, 72, 72, 73, 74, 75, 76, 76, 76, 77, 77, 77, 78, 79, 80, 81, 82, 83, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 87, 88, 88, 89, 90, 91, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 95, 96, 97, 98, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 105, 106, 107, 107, 107, 108, 108, 108, 109, 110, 110, 110, 111, 112, 112, 113, 114, 115, 116, 117, 118, 119, 119, 119, 120, 121, 122, 123, 124, 125, 126, 127, 127, 128, 128, 128, 128, 129, 129, 129, None]\n",
            "237 237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at pranav-s/PolymerNER and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-1-16dfe6ca56c7>:102: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2832898d963d444db4994c13b84bfc26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 168\n",
            "  Num Epochs = 100\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1100\n",
            "  Number of trainable parameters = 108896262\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1100/1100 29:43, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.351813</td>\n",
              "      <td>0.462921</td>\n",
              "      <td>0.438298</td>\n",
              "      <td>0.450273</td>\n",
              "      <td>0.896381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.215172</td>\n",
              "      <td>0.596899</td>\n",
              "      <td>0.655319</td>\n",
              "      <td>0.624746</td>\n",
              "      <td>0.929811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204281</td>\n",
              "      <td>0.638095</td>\n",
              "      <td>0.712766</td>\n",
              "      <td>0.673367</td>\n",
              "      <td>0.933069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.189528</td>\n",
              "      <td>0.687885</td>\n",
              "      <td>0.712766</td>\n",
              "      <td>0.700104</td>\n",
              "      <td>0.939231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.188789</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.943339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.187789</td>\n",
              "      <td>0.753846</td>\n",
              "      <td>0.729787</td>\n",
              "      <td>0.741622</td>\n",
              "      <td>0.944260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.203114</td>\n",
              "      <td>0.734151</td>\n",
              "      <td>0.763830</td>\n",
              "      <td>0.748697</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.213683</td>\n",
              "      <td>0.746392</td>\n",
              "      <td>0.770213</td>\n",
              "      <td>0.758115</td>\n",
              "      <td>0.944047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.216680</td>\n",
              "      <td>0.742394</td>\n",
              "      <td>0.778723</td>\n",
              "      <td>0.760125</td>\n",
              "      <td>0.941781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.247724</td>\n",
              "      <td>0.722656</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.753564</td>\n",
              "      <td>0.940010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.245562</td>\n",
              "      <td>0.748466</td>\n",
              "      <td>0.778723</td>\n",
              "      <td>0.763295</td>\n",
              "      <td>0.941568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.265699</td>\n",
              "      <td>0.753684</td>\n",
              "      <td>0.761702</td>\n",
              "      <td>0.757672</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.245569</td>\n",
              "      <td>0.741414</td>\n",
              "      <td>0.780851</td>\n",
              "      <td>0.760622</td>\n",
              "      <td>0.941356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.262133</td>\n",
              "      <td>0.744898</td>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.942630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.257770</td>\n",
              "      <td>0.760649</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.778816</td>\n",
              "      <td>0.943622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.274436</td>\n",
              "      <td>0.751004</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.941922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.277769</td>\n",
              "      <td>0.759109</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.778008</td>\n",
              "      <td>0.944189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.269978</td>\n",
              "      <td>0.756148</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.770355</td>\n",
              "      <td>0.944968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>0.749004</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.773663</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.280413</td>\n",
              "      <td>0.727447</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.764884</td>\n",
              "      <td>0.942135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.280968</td>\n",
              "      <td>0.765657</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.785492</td>\n",
              "      <td>0.945109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.289092</td>\n",
              "      <td>0.750996</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.775720</td>\n",
              "      <td>0.943976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275388</td>\n",
              "      <td>0.738462</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>0.775758</td>\n",
              "      <td>0.944755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.294774</td>\n",
              "      <td>0.773006</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.788321</td>\n",
              "      <td>0.944826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.300253</td>\n",
              "      <td>0.758551</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.779731</td>\n",
              "      <td>0.942772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.310545</td>\n",
              "      <td>0.757339</td>\n",
              "      <td>0.823404</td>\n",
              "      <td>0.788991</td>\n",
              "      <td>0.943693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.306232</td>\n",
              "      <td>0.755647</td>\n",
              "      <td>0.782979</td>\n",
              "      <td>0.769070</td>\n",
              "      <td>0.942206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.303166</td>\n",
              "      <td>0.753968</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.780287</td>\n",
              "      <td>0.943764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.311845</td>\n",
              "      <td>0.752988</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.945534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.317773</td>\n",
              "      <td>0.747554</td>\n",
              "      <td>0.812766</td>\n",
              "      <td>0.778797</td>\n",
              "      <td>0.943905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.316996</td>\n",
              "      <td>0.761711</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.778356</td>\n",
              "      <td>0.945534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.321963</td>\n",
              "      <td>0.733459</td>\n",
              "      <td>0.825532</td>\n",
              "      <td>0.776777</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.313561</td>\n",
              "      <td>0.747967</td>\n",
              "      <td>0.782979</td>\n",
              "      <td>0.765073</td>\n",
              "      <td>0.944047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.333927</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.942843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.323850</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.775130</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.335083</td>\n",
              "      <td>0.752535</td>\n",
              "      <td>0.789362</td>\n",
              "      <td>0.770509</td>\n",
              "      <td>0.944260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.325992</td>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.777202</td>\n",
              "      <td>0.945605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.312229</td>\n",
              "      <td>0.705224</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.751491</td>\n",
              "      <td>0.943197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.330871</td>\n",
              "      <td>0.762887</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.774869</td>\n",
              "      <td>0.944826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340073</td>\n",
              "      <td>0.746615</td>\n",
              "      <td>0.821277</td>\n",
              "      <td>0.782168</td>\n",
              "      <td>0.943905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.327637</td>\n",
              "      <td>0.752016</td>\n",
              "      <td>0.793617</td>\n",
              "      <td>0.772257</td>\n",
              "      <td>0.944189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.327130</td>\n",
              "      <td>0.756000</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.779381</td>\n",
              "      <td>0.944897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.339470</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.781443</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.343986</td>\n",
              "      <td>0.748000</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.771134</td>\n",
              "      <td>0.943410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.349670</td>\n",
              "      <td>0.745020</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.769547</td>\n",
              "      <td>0.942985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.354155</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.784969</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.361112</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.819149</td>\n",
              "      <td>0.793814</td>\n",
              "      <td>0.945605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.363600</td>\n",
              "      <td>0.764471</td>\n",
              "      <td>0.814894</td>\n",
              "      <td>0.788877</td>\n",
              "      <td>0.944968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.348949</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.943480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.349040</td>\n",
              "      <td>0.737154</td>\n",
              "      <td>0.793617</td>\n",
              "      <td>0.764344</td>\n",
              "      <td>0.943976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.347130</td>\n",
              "      <td>0.751491</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.776978</td>\n",
              "      <td>0.945039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.755511</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.778122</td>\n",
              "      <td>0.944826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.354067</td>\n",
              "      <td>0.754980</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.779835</td>\n",
              "      <td>0.944897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.358104</td>\n",
              "      <td>0.750499</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.774459</td>\n",
              "      <td>0.944543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.363812</td>\n",
              "      <td>0.754491</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.778579</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.370156</td>\n",
              "      <td>0.751984</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.778234</td>\n",
              "      <td>0.945039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.374806</td>\n",
              "      <td>0.747515</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.772867</td>\n",
              "      <td>0.943622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.372738</td>\n",
              "      <td>0.743083</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.942985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.369132</td>\n",
              "      <td>0.738703</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.768131</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.371848</td>\n",
              "      <td>0.753012</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.774793</td>\n",
              "      <td>0.945039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.376678</td>\n",
              "      <td>0.748527</td>\n",
              "      <td>0.810638</td>\n",
              "      <td>0.778345</td>\n",
              "      <td>0.943905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.378798</td>\n",
              "      <td>0.750980</td>\n",
              "      <td>0.814894</td>\n",
              "      <td>0.781633</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.373034</td>\n",
              "      <td>0.745020</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.769547</td>\n",
              "      <td>0.944543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.369132</td>\n",
              "      <td>0.741617</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.769703</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.373937</td>\n",
              "      <td>0.740234</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.771894</td>\n",
              "      <td>0.943693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.383468</td>\n",
              "      <td>0.739645</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.767656</td>\n",
              "      <td>0.943197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.380498</td>\n",
              "      <td>0.747495</td>\n",
              "      <td>0.793617</td>\n",
              "      <td>0.769866</td>\n",
              "      <td>0.943835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.381753</td>\n",
              "      <td>0.740964</td>\n",
              "      <td>0.785106</td>\n",
              "      <td>0.762397</td>\n",
              "      <td>0.943410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.380595</td>\n",
              "      <td>0.732422</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.763747</td>\n",
              "      <td>0.943126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.375183</td>\n",
              "      <td>0.738956</td>\n",
              "      <td>0.782979</td>\n",
              "      <td>0.760331</td>\n",
              "      <td>0.944897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.368161</td>\n",
              "      <td>0.753012</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.774793</td>\n",
              "      <td>0.944472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.373606</td>\n",
              "      <td>0.733728</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.761515</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.377462</td>\n",
              "      <td>0.734531</td>\n",
              "      <td>0.782979</td>\n",
              "      <td>0.757981</td>\n",
              "      <td>0.943764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.380203</td>\n",
              "      <td>0.745491</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.767802</td>\n",
              "      <td>0.944401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.387058</td>\n",
              "      <td>0.745562</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.773797</td>\n",
              "      <td>0.944755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.386873</td>\n",
              "      <td>0.745059</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.772541</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.390356</td>\n",
              "      <td>0.746032</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.772074</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.389599</td>\n",
              "      <td>0.759109</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.778008</td>\n",
              "      <td>0.945464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.392616</td>\n",
              "      <td>0.754527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.775595</td>\n",
              "      <td>0.945322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.390004</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.776181</td>\n",
              "      <td>0.944968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.390331</td>\n",
              "      <td>0.751984</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.778234</td>\n",
              "      <td>0.944968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.390902</td>\n",
              "      <td>0.753968</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.780287</td>\n",
              "      <td>0.945039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.390470</td>\n",
              "      <td>0.750495</td>\n",
              "      <td>0.806383</td>\n",
              "      <td>0.777436</td>\n",
              "      <td>0.944826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.387154</td>\n",
              "      <td>0.752495</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.776519</td>\n",
              "      <td>0.944897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.388450</td>\n",
              "      <td>0.744554</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.771282</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.392841</td>\n",
              "      <td>0.747036</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.774590</td>\n",
              "      <td>0.944684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.392575</td>\n",
              "      <td>0.747036</td>\n",
              "      <td>0.804255</td>\n",
              "      <td>0.774590</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.393337</td>\n",
              "      <td>0.747515</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.772867</td>\n",
              "      <td>0.944614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.393629</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.791489</td>\n",
              "      <td>0.767010</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.068900</td>\n",
              "      <td>0.393380</td>\n",
              "      <td>0.741551</td>\n",
              "      <td>0.793617</td>\n",
              "      <td>0.766701</td>\n",
              "      <td>0.944330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.390189</td>\n",
              "      <td>0.747515</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.772867</td>\n",
              "      <td>0.944189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.386019</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.386011</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.386279</td>\n",
              "      <td>0.749004</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.773663</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.386754</td>\n",
              "      <td>0.743539</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.768756</td>\n",
              "      <td>0.943976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.386880</td>\n",
              "      <td>0.743539</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.768756</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.387432</td>\n",
              "      <td>0.743539</td>\n",
              "      <td>0.795745</td>\n",
              "      <td>0.768756</td>\n",
              "      <td>0.943976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.387518</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.944189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.387339</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.387420</td>\n",
              "      <td>0.745527</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.770812</td>\n",
              "      <td>0.944118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to PolymerNER-finetuned-ner/checkpoint-500\n",
            "Configuration saved in PolymerNER-finetuned-ner/checkpoint-500/config.json\n",
            "Model weights saved in PolymerNER-finetuned-ner/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in PolymerNER-finetuned-ner/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in PolymerNER-finetuned-ner/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to PolymerNER-finetuned-ner/checkpoint-1000\n",
            "Configuration saved in PolymerNER-finetuned-ner/checkpoint-1000/config.json\n",
            "Model weights saved in PolymerNER-finetuned-ner/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in PolymerNER-finetuned-ner/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in PolymerNER-finetuned-ner/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_NAME seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPERTY_VALUE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CO-CATALYST seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1100, training_loss=0.036563156788999386, metrics={'train_runtime': 1789.4141, 'train_samples_per_second': 9.389, 'train_steps_per_second': 0.615, 'total_flos': 4389944264294400.0, 'train_loss': 0.036563156788999386, 'epoch': 100.0})"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Bs5L-Ji3pFJL",
        "outputId": "3e53efa8-d2c1-4357-8d72-106871fb1050"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.38741952180862427,\n",
              " 'eval_precision': 0.7455268389662028,\n",
              " 'eval_recall': 0.7978723404255319,\n",
              " 'eval_f1': 0.7708119218910585,\n",
              " 'eval_accuracy': 0.9441178553721935,\n",
              " 'eval_runtime': 1.7517,\n",
              " 'eval_samples_per_second': 23.976,\n",
              " 'eval_steps_per_second': 1.713,\n",
              " 'epoch': 100.0}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, _ = trainer.predict(tokenized_datasets[\"valid\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "hCXr1nlbpHuH",
        "outputId": "c3796e77-9375-40f1-fc06-6c0315699a54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 42\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ATALYST': {'precision': 0.6157635467980296,\n",
              "  'recall': 0.7062146892655368,\n",
              "  'f1': 0.6578947368421053,\n",
              "  'number': 177},\n",
              " 'CATALYST': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 7},\n",
              " 'ROPERTY_NAME': {'precision': 0.8142857142857143,\n",
              "  'recall': 0.8636363636363636,\n",
              "  'f1': 0.8382352941176471,\n",
              "  'number': 132},\n",
              " 'ROPERTY_VALUE': {'precision': 0.85,\n",
              "  'recall': 0.8831168831168831,\n",
              "  'f1': 0.8662420382165604,\n",
              "  'number': 154},\n",
              " 'overall_precision': 0.7455268389662028,\n",
              " 'overall_recall': 0.7978723404255319,\n",
              " 'overall_f1': 0.7708119218910585,\n",
              " 'overall_accuracy': 0.9441178553721935}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}